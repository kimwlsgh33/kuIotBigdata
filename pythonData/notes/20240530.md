# 오렌지 실습

머신러닝 : 지도학습[Target] ---> 각종이름 ->학습결과->모델

O , X

# TODO:

# 머신러닝 (Machine Learning)

머신러닝은 컴퓨터가 명시적으로 프로그래밍되지 않고도 데이터를 통해 학습하고 예측할 수 있도록 하는 인공지능(AI)의 한 분야입니다. 즉, 컴퓨터가 데이터에서 패턴을 인식하고, 그 패턴을 기반으로 새로운 데이터에 대해 결정을 내리거나 예측을 하는 기술입니다. 머신러닝은 크게 세 가지 주요 유형으로 나뉩니다: 지도학습, 비지도학습, 강화학습.

1. 지도학습 (Supervised Learning)

지도학습은 입력 데이터와 해당 데이터에 대한 정답(라벨)이 주어질 때, 이 데이터를 바탕으로 새로운 입력 데이터에 대한 예측을 수행하는 학습 방식입니다. 대표적인 지도학습 알고리즘은 다음과 같습니다:

- 선형 회귀 (Linear Regression)
- 로지스틱 회귀 (Logistic Regression)
- 서포트 벡터 머신 (Support Vector Machine, SVM)
- 결정 트리 (Decision Tree)
- 랜덤 포레스트 (Random Forest)
- k-최근접 이웃 (k-Nearest Neighbors, k-NN)

지도학습은 분류(Classification)와 회귀(Regression) 문제로 나뉩니다. 분류는 입력 데이터를 특정 카테고리로 분류하는 것이며, 회귀는 연속적인 값을 예측하는 것입니다.

2. 비지도학습 (Unsupervised Learning)

비지도학습은 입력 데이터만 주어지고 정답(라벨)은 주어지지 않을 때, 데이터의 구조를 학습하는 방식입니다. 대표적인 비지도학습 알고리즘은 다음과 같습니다:

- 군집화 (Clustering): K-평균 (K-Means), 계층적 군집화 (Hierarchical Clustering)
- 차원 축소 (Dimensionality Reduction): 주성분 분석 (Principal Component Analysis, PCA), t-SNE

비지도학습의 목표는 데이터의 숨겨진 패턴이나 구조를 발견하는 것입니다.

3. 강화학습 (Reinforcement Learning)

강화학습은 에이전트(Agent)가 환경과 상호작용하면서 보상(Reward)을 최대화하는 행동을 학습하는 방식입니다. 에이전트는 일련의 행동을 통해 환경을 탐색하며, 각 행동의 결과로부터 보상을 받아 정책(Policy)을 개선해 나갑니다. 대표적인 강화학습 알고리즘은 다음과 같습니다:

Q-러닝 (Q-Learning)
심층 Q-네트워크 (Deep Q-Network, DQN)
정책 경사 (Policy Gradient) 방법

머신러닝의 주요 과정

1. 데이터 수집 (Data Collection): 문제를 해결하기 위한 데이터를 수집합니다.
2. 데이터 전처리 (Data Preprocessing): 결측치 처리, 데이터 정규화, 범주형 데이터 인코딩 등 데이터를 정리합니다.
3. 특징 선택 (Feature Selection): 모델 학습에 유용한 특징을 선택하거나 생성합니다.
4. 모델 선택 (Model Selection): 문제에 맞는 머신러닝 알고리즘을 선택합니다.
5. 모델 학습 (Model Training): 훈련 데이터를 사용해 모델을 학습시킵니다.
6. 모델 평가 (Model Evaluation): 검증 데이터를 사용해 모델의 성능을 평가합니다.
7. 하이퍼파라미터 튜닝 (Hyperparameter Tuning): 모델의 성능을 최적화하기 위해 하이퍼파라미터를 조정합니다.
8. 모델 테스트 (Model Testing): 테스트 데이터를 사용해 최종 모델의 성능을 평가합니다.
9. 배포 및 모니터링 (Deployment and Monitoring): 모델을 실제 환경에 배포하고 성능을 지속적으로 모니터링합니다.

지도학습 [Supervised Learning] \* 지도학습은 머신러닝의 한 종류로, 입력 데이터와 해당 데이터에 대한 정답(라벨)이 함께 주어질 때, 이 데이터를 바탕으로 새로운 입력 데이터에 대한 예측을 수행하는 학습 방식입니다. 지도학습의 주요 목표는 주어진 입력 데이터와 출력 데이터 간의 관계를 학습하는 모델을 만드는 것입니다. 지도학습은 크게 두 가지로 나뉩니다:

1. 분류 (Classification): 입력 데이터를 특정 카테고리(클래스)로 분류하는 것. 예를 들어, 이메일이 스팸인지 아닌지를 분류하거나, 이미지가 고양이인지 개인지 판별하는 작업이 이에 해당합니다.
2. 회귀 (Regression): 연속적인 값을 예측하는 것. 예를 들어, 주택 가격을 예측하거나 주식 시장 가격을 예측하는 작업이 이에 해당합니다.

지도학습의 예시:

분류

- 스팸 필터: 이메일 데이터를 입력으로 받아서 스팸인지 아닌지를 예측.
- 이미지 분류: 이미지 데이터를 입력으로 받아서 이미지의 카테고리를 예측.
- 의료 진단: 환자의 의료 데이터를 입력으로 받아서 특정 질병의 유무를 예측.

회귀

- 주택 가격 예측: 주택의 크기, 위치, 방 수 등의 데이터를 입력으로 받아서 주택의 가격을 예측.
- 주식 가격 예측: 과거 주식 가격 데이터를 입력으로 받아서 미래 주식 가격을 예측.
- 기온 예측: 기상 데이터를 입력으로 받아서 미래의 기온을 예측.

지도학습 과정

1. 데이터 수집: 입력 데이터(X)와 해당 데이터에 대한 정답(라벨, Y)을 수집합니다.
2. 데이터 전처리: 결측치 처리, 정규화, 데이터 변환 등 데이터를 모델에 맞게 전처리합니다.
3. 모델 선택: 문제에 적합한 알고리즘을 선택합니다 (예: 로지스틱 회귀, SVM, 결정 트리 등).
4. 모델 학습: 훈련 데이터를 사용하여 모델을 학습시킵니다.
5. 모델 평가: 검증 데이터를 사용하여 모델의 성능을 평가합니다 (예: 정확도, MSE 등).
6. 하이퍼파라미터 튜닝: 모델의 성능을 최적화하기 위해 하이퍼파라미터를 조정합니다.
7. 모델 테스트: 테스트 데이터를 사용하여 최종 모델의 성능을 평가합니다.
8. 배포: 모델을 실제 환경에 배포하여 새로운 데이터를 예측합니다.

아이리스 데이터셋의 세 가지 품종

1. Setosa
2. Versicolor
3. Virginica

Python을 사용하여 지도학습의 간단한 예시. 아이리스 데이터셋을 사용하여 꽃의 품종을 분류하는 로지스틱 회귀 모델을 학습하는 코드입니다.

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 데이터 로드

iris = load_iris()
X = iris.data
y = iris.target

# 데이터 분할

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 데이터 표준화

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 로지스틱 회귀 모델 훈련

model = LogisticRegression()
model.fit(X_train, y_train)

# 예측

y_pred = model.predict(X_test)

# 정확도 평가

accuracy = accuracy_score(y_test, y_pred)
print(f'모델 정확도: {accuracy \* 100:.2f}%')

이 코드는 아이리스 데이터셋을 로드하고, 데이터를 훈련 및 테스트 세트로 분할한 후, 로지스틱 회귀 모델을 훈련시키고, 테스트 데이터에 대한 예측 정확도를 계산한다.

-----다시 데이터과학을 위한 통계 시작 -------------------------------3장-----------

chap3 통계적 실험과 유의성검정 BEGIN

- 유의성 검정 (Significance Testing)

  유의성 검정은 통계학에서 특정 가설을 검증하기 위해 사용되는 방법입니다. 이 검정은 실험이나 관측 데이터를 분석하여, 관찰된 효과가 우연에 의한 것인지 아니면 실제로 유의미한 것인지 판단하는 데 사용됩니다. 유의성 검정은 두 가지 가설, 즉 귀무가설 (null hypothesis)과 대립가설 (alternative hypothesis)로 시작합니다.

\*\* 귀무가설 (Null Hypothesis, H0H0​)

    귀무가설은 보통 "효과가 없다" 또는 "두 집단 간 차이가 없다"라는 진술을 포함합니다. 예를 들어, 신약의 효과가 기존 약과 차이가 없다는 가설이 귀무가설이 될 수 있습니다.

\*\* 대립가설 (Alternative Hypothesis, H1H1​)

    대립가설은 "효과가 있다" 또는 "두 집단 간 차이가 있다"라는 진술을 포함합니다. 신약의 효과가 기존 약보다 우수하다는 가설이 대립가설이 될 수 있습니다.

\*\* 유의수준 (Significance Level, αα)

    유의수준은 귀무가설을 기각할 기준이 되는 확률값입니다. 일반적으로 α=0.05α=0.05를 많이 사용하며, 이는 5%의 확률로 귀무가설이 참임에도 불구하고 기각하는 것을 허용합니다.

\*\* 검정통계량 (Test Statistic)

    검정통계량은 관찰된 데이터로부터 계산되는 값으로, 귀무가설이 참일 때의 분포를 따릅니다. 검정통계량의 예로는 t-값, z-값, chi-제곱 값 등이 있습니다.

\*\* p-값 (p-value)

    p-값은 관찰된 데이터가 귀무가설 하에서 얼마나 일어날 가능성이 있는지를 나타내는 확률입니다. p-값이 유의수준 αα보다 작으면 귀무가설을 기각하고, 대립가설을 채택합니다.

\*\* 유의성 검정의 단계

    1. 가설 설정: 귀무가설과 대립가설을 설정합니다.
    2. 유의수준 설정: 일반적으로 α=0.05α=0.05로 설정합니다.
    3. 검정통계량 계산: 데이터를 기반으로 검정통계량을 계산합니다.
    4. p-값 계산: 검정통계량에 해당하는 p-값을 계산합니다.
    5. 결론 도출: p-값이 유의수준 αα보다 작으면 귀무가설을 기각합니다.


    - 3.1 A/B 검정 (A/B Testing)

        - A/B 검정은 두 가지 버전(A와 B)의 변형을 비교하여 어느 것이 더 나은 성과를 내는지 평가하는 실험 방법입니다. A/B 검정은 마케팅, 웹사이트 최적화, 사용자 경험 연구 등 다양한 분야에서 널리 사용됩니다. 이 방법은 과학적이고 통계적인 접근을 통해 어떤 변화가 성과에 영향을 미치는지 확인한다.

        **용어 정리**
        -처리 (treatement) : 어떤 대상에 주어지는 특별한 환경이나 조건
        -처리군(처리그룹)[treatement group] :특정 처리에 노출된 대상들의 집단
        -대조군(대조그룹)[control group] : 어떤처리도 하지않은 대상들의 집단
        -임의화(랜덤화)[randomization] : 처리를 적용할 대상을 임의로 결정하는과정
        -대상[subject] : 처리를 적용할 개체대상(유의어:피실험자)
        -검정통계량[test statistic] : 처리 효과를 측정하기 위한 지표

        3.1.1 대조군 (Control Group)이 필요한 이유

            - 대조군은 실험에서 비교 기준을 제공하는 그룹입니다. 실험군과 비교하여 변화나 처치의 효과를 평가하기 위해 사용됩니다. 대조군이 필요한 이유는 다음과 같습니다:

                1.비교 기준 제공:
                    대조군은 실험군과 비교할 수 있는 기준을 제공합니다. 이를 통해 실험군에서 관찰된 변화가 실제로 처치나 변화에 의한 것인지, 아니면 다른 요인에 의한 것인지를 판단할 수 있습니다.
                2. 변수 통제:
                    대조군을 사용함으로써 실험 조건 외의 다른 변수들이 실험 결과에 미치는 영향을 최소화할 수 있습니다. 이는 결과의 신뢰성을 높여줍니다.
                3. 효과 측정:
                    대조군과 실험군 간의 차이를 통해 특정 처치나 변화의 효과를 정량적으로 측정할 수 있습니다.

                예를 들어, 새로운 약물의 효과를 테스트할 때 대조군은 기존 약물 또는 플라시보를 받는 그룹이 됩니다. 이를 통해 새로운 약물이 실제로 더 나은 효과를 발휘하는지 비교할 수 있다.

        3.1.2 왜 A/B 테스트인가? (C/D 테스트가 아닌 이유)

            - A/B 테스트라는 용어는 단순히 두 가지 변형(A와 B)을 비교하는 것을 의미합니다. 이 용어가 널리 사용되는 이유는 다음과 같습니다:

                1.단순성:
                    A/B 테스트는 가장 기본적이고 단순한 형태의 비교 실험입니다. 두 가지 변형만을 비교하기 때문에 실험 설계와 분석이 간단합니다.
                2.명확한 결과:
                    두 가지 선택지(A와 B)만을 비교하기 때문에 결과 해석이 명확합니다. 이는 빠르고 확실한 결정을 내리는 데 유리합니다.
                3.역사적 이유:
                    A/B 테스트라는 용어는 오랜 기간 동안 마케팅, 웹사이트 최적화, 사용자 경험 연구 등 다양한 분야에서 사용되어 왔습니다. 이 용어는 이미 널리 이해되고 받아들여지고 있습니다.

        요약

            ** 대조군: 비교 기준을 제공하여 실험 결과의 신뢰성을 높입니다.
            ** A/B 테스트: 두 가지 변형을 비교하는 기본적인 방법으로, 단순성과 명확성을 제공합니다.
            ** 여러 변형 비교: A/B/n 테스트를 통해 세 개 이상의 변형을 비교할 수 있으며, 이는 더 많은 데이터를 수집하고 다양한 옵션을 평가하는 데 유용합니다.

    3.2 가설검정 (Hypothesis Testing)

        가설검정은 주어진 데이터에 기초하여 특정 주장(가설)을 검증하는 통계적 방법입니다. 이는 연구나 실험에서 관찰된 현상이 우연에 의한 것인지, 아니면 실제로 의미 있는 것인지를 판단하는 데 사용됩니다. 가설검정은 두 가지 기본 가설, 즉 귀무가설 (null hypothesis, H0H0​)과 대립가설 (alternative hypothesis, H1H1​)로 시작됩니다.

        1. 기본 개념
            귀무가설 (H0H0​):
                일반적으로 "효과가 없다"거나 "차이가 없다"는 가설을 말합니다.
                예를 들어, 새로운 치료법이 기존 치료법과 효과가 동일하다는 가설.

            대립가설 (H1H1​):
                "효과가 있다"거나 "차이가 있다"는 가설을 말합니다.
                예를 들어, 새로운 치료법이 기존 치료법보다 효과적이라는 가설.

        2. 유의수준 (Significance Level, αα)

            유의수준은 가설검정에서 귀무가설을 기각할 기준이 되는 확률값입니다.
            일반적으로 α=0.05α=0.05를 많이 사용하며, 이는 5%의 확률로 귀무가설을 기각하는 오류(제1종 오류)를 허용한다는 의미입니다.

        3. 검정통계량 (Test Statistic)

            검정통계량은 관찰된 데이터로부터 계산된 값으로, 귀무가설이 참일 때의 분포를 따릅니다.
            (예를 들어, t-값, z-값, chi-제곱 값 등이 있습니다.)

        4. p-값 (p-value)

        p-값은 관찰된 데이터가 귀무가설 하에서 발생할 확률입니다.
        p-값이 유의수준 αα보다 작으면, 귀무가설을 기각하고 대립가설을 채택합니다.

    **용어정리**
        -귀무가설(null hypothesis): 우연 때문이라는 가설(유의어 : 영가설)
        -대립가설(alternative hypothesis) : 귀무가설과의 대조(증명하고자하는 가설)
        -일원검정(one-way test): 한방향으로만 우연히 일어날 확률을 계산하는 가설검정
        -이원검정(two-way test): 양방향으로 우연히 일어날 확률을 계산하는 가설검정

    **가설검정의 절차**
        1. 가설 설정:
            귀무가설 (H0H0​)과 대립가설 (H1H1​)을 명확히 설정합니다.
        2. 유의수준 설정:
            일반적으로 α=0.05α=0.05를 설정합니다.
        3. 데이터 수집:
            검정을 수행하기 위해 필요한 데이터를 수집합니다.
        4. 검정통계량 계산:
            수집된 데이터를 바탕으로 검정통계량을 계산합니다.
        5. p-값 계산:
            검정통계량에 해당하는 p-값을 계산합니다.
        6. 결론 도출:
            p-값이 유의수준 αα보다 작으면 귀무가설을 기각하고 대립가설을 채택합니다.

    3.2.1 귀무가설
        - 귀무가설은 가설검정에서의 중요한 개념으로, 대립가설과 반대되는 가설을 나타냅니다. 주로 "효과가 없다" 또는 "차이가 없다"는 가설로 설정되며, 연구나 실험을 통해 주장하고자 하는 가설에 대립하는 명제입니다.

        귀무가설은 H0H0​로 표기되며, 일반적으로 연구자가 주장하고자 하는 가설인 대립가설과 반대되는 내용을 가지고 있습니다. 가설검정의 목적은 귀무가설의 참/거짓을 결정하는 것입니다. 만약 귀무가설이 기각된다면, 대립가설을 받아들일 수 있습니다.

    3.2.2 대립가설 (Alternative Hypothesis)

        - 대립가설은 가설검정에서 검정하고자 하는 주장이나 이론을 나타냅니다. 보통은 연구자가 주장하고자 하는 가설로, 특정 변수 간에 관계나 차이가 있다는 것을 나타냅니다.
        예를 들어, 어떤 신약이 기존 약보다 더 효과적이라는 주장은 대립가설로 나타낼 수 있습니다. 이 대립가설은 통계적 검정을 통해 데이터를 통해 지지되거나 기각될 수 있습니다.

    3.2.3 일원가설검정 (One-Tailed Test)

        -일원가설검정은 가설검정의 유형 중 하나로, 대립가설이 양측(양쪽) 방향으로만 주장되는 경우를 나타냅니다. 즉, 대립가설은 변수 간에 방향성이 있는 차이를 주장하며, 이 차이가 양측으로 나타날 수 있습니다.
        일원가설검정에서는 귀무가설을 기각하는 기준이 특정 방향에만 존재합니다. 따라서 가설검정 결과가 양측으로 비대칭적인 경우에 사용됩니다.
        예를 들어, 어떤 신약이 기존 약보다 더 높은 효과를 보인다는 주장을 한다면, 대립가설은 "신약의 효과는 기존 약보다 크다"로 설정되고, 이는 일원가설검정으로 검증될 수 있습니다.

        **이원가설검정 (Two-Tailed Test)

        - 이원가설검정은 대립가설이 양측 방향으로 주장될 수 있는 경우에 사용됩니다. 즉, 대립가설은 변수 간에 차이가 있는지만을 주장하며, 이 차이가 양측으로 나타날 수 있습니다.
        이원가설검정에서는 귀무가설을 기각하는 기준이 양쪽 모두에 존재하며, 양측으로의 비대칭적인 결과에 사용됩니다.
        예를 들어, 어떤 신약이 기존 약과 다른 효과를 보인다는 주장을 한다면, 대립가설은 "신약의 효과는 기존 약과 다르다"로 설정되고, 이는 이원가설검정으로 검증될 수 있습니다.

    3.3 재표본추출(Resampling)

        - 재표본추출은 통계적 추론을 위해 주어진 데이터에서 반복적으로 표본을 추출하는 과정을 말합니다. 이를 통해 주어진 데이터셋으로부터 여러 개의 표본을 생성하고, 이를 활용하여 통계량이나 추정치의 분포를 조사하거나 가설검정을 수행할 수 있습니다.

        주요 재표본추출 방법으로는 부트스트래핑(bootstrapping)과 재표본추출(permuation)이 있습니다. 부트스트래핑은 복원추출 방식으로 표본을 추출하는 반면, 재표본추출은 복원추출 없이 주어진 데이터를 순열하여 새로운 표본을 생성합니다.

    **용어정리**
        -순열검정(permutation test) : 두개 이상의 표본을 함께결합하여관측값들을 무작위로 재표본으로 추출하는 과정을 말한다.[유의어:임의화검정, 임의순열검정, 정확검정]
        -재표본추출(resampling) : 관측 데이터로부터 반복해서 표본추출하는 과정.
        -복원/비복원(with or without replacement) : 표본을 추출할 때, 이미 한번 뽑은 데이터를 다음번 추출을 위해 다시 제자리에 돌려놓거나 다음 추출에서 제외하는 표본추출 방법.

            3.3.1 순열검정 (Permutation Test)

                - 순열검정은 통계적 가설검정의 한 방법으로, 표본 데이터를 재표본추출을 통해 생성된 표본들로 재표본추출된 통계량을 비교함으로써 가설을 검정합니다.
                순열검정은 가설검정을 위해 임의의 표본을 생성하는 과정을 거치기 때문에, 표본분포가 표본크기가 충분히 클 때 중심극한정리에 의해 정규분포를 따르지 않아도 되는 장점이 있습니다.

            3.3.2 웹 점착성(Web Stickiness)

                -웹 점착성은 웹사이트나 앱의 이용자가 그 서비스에 얼마나 오래 머무르는지를 나타내는 지표입니다. 이는 방문자가 웹사이트에서 얼마나 많은 시간을 보내는지, 페이지를 얼마나 자주 방문하는지, 사용자들이 얼마나 자주 상호 작용하는지 등을 포함합니다. 높은 웹 점착성은 사용자들이 서비스에 충성하고 활발하게 참여한다는 것을 나타내며, 기업이나 기관에게 중요한 지표 중 하나.

            3.3.3 전체 및 부트스트랩 순열검정

                - 순열검정은 통계적 가설검정 방법 중 하나로, 관측된 데이터의 순서를 무작위로 바꾸어 가설을 검정하는 방법입니다. 이를 통해 표본의 크기가 작거나 분포에 대한 가정이 충족되지 않을 때도 유효한 검정을 수행할 수 있습니다.

                * 전체 순열검정 (Exact Permutation Test):
                    -모든 가능한 표본 순열을 고려하여 검정하는 방법입니다. 데이터셋이 작거나 가능한 표본 공간이 비교적 작을 때 사용됩니다. 가능한 모든 조합을 고려하기 때문에 정확한 p-값을 얻을 수 있지만, 계산 비용이 매우 높을 수 있습니다.

                * 부트스트랩 순열검정 (Bootstrap Permutation Test):
                    -부트스트랩 순열검정은 전체 순열검정의 계산 비용을 줄이기 위해 사용됩니다. 관측된 데이터로부터 복원추출을 통해 여러 재표본을 생성하고, 각 재표본에 대해 순열검정을 수행합니다. 이를 통해 근사적인 p-값을 얻을 수 있으며, 계산 비용이 낮아 전체 순열검정에 비해 효율적입니다.

    3.4 통계적 유의성과 p값

        -통계적 유의성 (Statistical Significance)

            통계적 유의성은 주어진 데이터에서 관찰된 차이나 관계가 우연에 의한 것이 아니라 실제로 의미 있는 것인지를 나타내는 지표입니다. 즉, 연구나 실험 결과가 우연에 의한 것이 아니라 진짜로 의미 있는지를 판단하는 것입니다.
            통계적 유의성은 주로 p-값과 유의수준을 통해 결정됩니다. 유의수준은 연구자가 미리 설정하는 임계값으로, 일반적으로 0.05 또는 0.01이 많이 사용됩니다. p-값이 유의수준보다 작으면, 우연히 나타날 확률이 매우 낮기 때문에 해당 결과가 통계적으로 유의하다고 판단됩니다.

        **용어정리**
            - p값[p-value] : 귀마가설을 구체화한 기회모델이 주어졌을떄 관측된 결과와 같이 특이하거나극단적인결과를 얻을 확률
            - 알파[alpha] : 실제결과가 통계적으로 의미있는것으로 간주되기 위해, 우연에 의한 결과가 능가해야하는 '비정상적인' 가능성의 임계확률
            - 제1종 오류[type 1 error] : 우연에 의한 효과를 실제효과라고 잘못 결론내리는 것
            - 제2종 오류 [type 2 error] : 실제효과를 우연에 의한 효과라고 잘못 결론 내리는 것

        3.4.1 p값
            - p-값 (p-value)

                p-값은 귀무가설이 참일 때, 관측된 데이터나 더 극단적인 데이터가 관측될 확률을 나타냅니다. 즉, p-값은 귀무가설을 기각하는데 필요한 증거의 강도를 나타내는 지표입니다. 작은 p-값은 귀무가설을 기각하는 강력한 증거를 제공하며, 이는 관찰된 데이터가 우연에 의한 것이 아니라는 것을 나타냅니다.
                일반적으로, p-값이 유의수준보다 작을수록 (예: 0.05), 해당 결과가 통계적으로 유의하다고 판단됩니다. 따라서 작은 p-값은 우연에 의한 것이 아니라는 증거를 제공하여 통계적으로 유의한 결과를 나타냅니다.

        3.4.2 유의수준 (Significance Level)

            -유의수준은 통계적 가설검정에서 사용되는 중요한 개념으로, 귀무가설이 참인데도 불구하고 해당 가설을 잘못 기각할 확률을 나타냅니다. 일반적으로 알파(α)로 표기되며, 가설을 검정하는 데 사용되는 임계값입니다.
            가장 흔히 사용되는 유의수준은 0.05와 0.01입니다. 유의수준이 0.05인 경우, 귀무가설이 참일 때 해당 가설을 잘못 기각할 확률이 5% 이하라는 것을 의미합니다.

        3.4.3 제1종 오류와 제2종 오류 (Type I and Type II Errors)

            - 제1종 오류 (Type I Error): 귀무가설이 참인데도 불구하고 해당 가설을 잘못 기각하는 오류입니다. 유의수준과 관련이 있으며, 유의수준을 낮추면 제1종 오류의 발생 확률이 줄어듭니다.
            - 제2종 오류 (Type II Error): 귀무가설이 거짓인데도 불구하고 해당 가설을 기각하지 않는 오류입니다. 제2종 오류의 확률은 표본 크기, 효과의 크기 등 여러 요소에 의해 영향을 받습니다.

        3.4.4 데이터 과학과 p값

            -데이터 과학에서의 p-값은 통계적 가설검정에서 주로 사용되며, 가설을 검정하고 결과를 해석하는 데 중요한 역할을 합니다. p-값은 귀무가설을 참으로 가정했을 때, 관찰된 데이터 또는 더 극단적인 데이터가 나타날 확률을 나타냅니다.
            데이터 과학에서는 p-값을 사용하여 가설을 검정하고, 결과를 통계적으로 유의한지를 판단합니다. 일반적으로, 유의수준과 p-값을 비교하여 해당 결과가 통계적으로 유의한지를 결정합니다. p-값이 유의수준보다 작을수록 해당 결과가 계적으로 유의하다고 판단됩니다.
            예를 들어, 어떤 실험에서의 p-값이 0.03이고 유의수준이 0.05라면, 해당 결과는 통계적으로 유의하다고 할 수 있습니다. 따라서 귀무가설을 기각하고, 대립가설을 받아들일 수 있습니다.
            요약하자면, 유의수준은 가설검정에서 사용되는 임계값으로, 제1종 오류의 발생 확률을 나타내며, p-값은 가설을 검정하고 결과를 해석하는 데 사용되는 지표로, 유의수준과 비교하여 해당 결과가 통계적으로 유의한지를 판단하는 데 중요한 역할을 합니다.

    3.5 t 검정

        - t-검정은 두 집단 간의 평균 차이를 비교하는 통계적 방법 중 하나입니다. 주로 두 집단의 평균이 동일한지 여부를 확인하기 위해 사용됩니다.
        t-검정은 표본 평균 간의 차이를 표준 오차로 조정하여 검정 통계량(t-값)을 계산합니다. 이 t-값을 통해 두 집단 간의 평균 차이가 우연에 의한 것인지를 판단하며, 이를 통해 귀무가설을 기각하거나 채택합니다.

    일반적으로 t-검정은 다음과 같은 단계로 진행됩니다:

        1. 가설 설정: 귀무가설과 대립가설을 설정합니다. 귀무가설은 두 집단의 평균이 같다는 것을 나타내며, 대립가설은 두 집단의 평균이 다르다는 것을 나타냅니다.
        2. 표본 추출: 두 집단에서 표본을 추출합니다.
        3. 평균 및 표준 편차 계산: 각 집단의 표본 평균과 표준 편차를 계산합니다.
        4. t-값 계산: 두 집단 간의 평균 차이를 표준 오차로 조정하여 t-값을 계산합니다.
        5. 유의수준과 비교: 계산된 t-값을 유의수준과 비교하여 귀무가설을 기각하거나 채택합니다.
        6. 결과 해석: 귀무가설을 기각하면, 두 집단의 평균이 다르다고 결론을 내릴 수 있습니다.

        t-검정은 표본의 크기가 작거나 모집단의 표준 편차를 모를 때 주로 사용됩니다. 특히, 두 집단의 표본 크기가 비슷하고 정규분포를 따를 때 효과적으로 사용됩니다. t-검정은 학계와 실무에서 폭넓게 사용되며, 두 집단 간의 평균 차이를 비교하는 많은 분야에서 활용됩니다.

    3.6 다중검정 (Multiple Testing)

        다중검정은 여러 개의 가설을 동시에 검정하는 과정을 말합니다. 하나의 실험에서 여러 개의 가설을 검정하게 되면, 가설검정 과정에서 제1종 오류(가설이 참일 때 거짓으로 기각되는 오류)의 위험이 증가할 수 있습니다. 다중검정을 통해 이러한 위험을 줄이고 신뢰할 수 있는 검정 결과를 얻을 수 있습니다.

        다중검정에는 여러 가지 방법이 있으며, 대표적으로는 Bonferroni 수정, Holm-Bonferroni 방법, False Discovery Rate (FDR) 등이 있습니다. 이러한 방법들은 제1종 오류의 위험을 조절하거나 p-값을 조정하여 다중검정을 수행합니다.

        **용어 정리**
            -제1종 오류[type 1 error] : 어떤 효과가 통계적으로 유의미하다고 잘못되 결론을 내린다.
            -거짓발견비율[FDR : false discovery rate] : 다중검저에서 1종오류가 발생하는 비율
            -알파 인플레이션[alpha inflation] : 1종오류를 만들 확률인 알파가 더 많은 테스트를 수행할수록 증가하는 다중검정현상.
            -p값 조정[adjustment of p-value] : 동일한 데이터에 대해 다중검정을 수행하는 경우에 필요하다.
            -과대적립(오버피팅)[overfitting] : 잡음까지 피팅

        - 투기의 HSD(Honestly Significant Difference)는 다중비교에서 사용되는 통계적 기법 중 하나입니다. 이 방법은 ANOVA(분산분석)를 통해 그룹 간 평균의 차이가 통계적으로 유의한 경우, 어떤 그룹들이 서로 유의하게 다른지를 식별하는 데 사용됩니다.

        투기의 HSD는 각 그룹의 평균값들 사이의 최소 유의한 차이를 계산하여 비교합니다.  이 값은 각 그룹의 평균 차이가 두 개 이상의 그룹에서 특정한 기준값 이상인 경우에만 유의하다고 판단됩니다. 따라서, 그룹 간의 모든 가능한 조합에 대해 최소한의 유의한 차이를 계산하여 어떤 그룹들이 통계적으로 다른지를 판별하는 데 도움이 됩니다.

        투기의 HSD는 다중비교에 많이 사용되는 방법 중 하나로, 특히 ANOVA로 차이가 있는 그룹들을 식별하는 경우 유용합니다. 이 방법을 사용하면 다중비교에서 제1종 오류의 위험을 제어하면서 각 그룹 간의 평균 차이를 식별할 수 있습니다.

    3.7 자유도 (Degrees of Freedom)

        자유도는 통계 모형에서 모수를 추정할 때 사용되는 독립적인 정보의 수를 나타냅니다. 자유도는 모집단의 크기와 샘플의 크기 간의 관계에 따라 결정됩니다. 보통, 자유도는 샘플의 크기에서 추정된 모수의 수를 뺀 값입니다.

        예를 들어, t-검정에서는 자유도가 샘플의 크기에서 1을 뺀 값이 됩니다. 자유도가 높을수록 데이터에서 추정된 통계량의 분포가 모집단의 분포에 더 가깝습니다.

        **용어 정리**
        -표본크기 n : 해당 데이터에서 관측값의 개수(행 혹은 기록값의 개수와 같은 의미)
        - d.f.[degrees of freedom] : 자유도

    3.8 분산분석 (Analysis of Variance, ANOVA)

        분산분석은 세 개 이상의 집단 간의 평균 차이를 비교하는 통계적 방법입니다. ANOVA는 각 집단의 평균값이 동일한 모집단에서 추출된 것인지를 검정합니다.

        ANOVA는 전체 변동을 그룹 간 변동과 그룹 내 변동으로 분해하여 F-통계량을 계산하고 이를 통해 가설을 검정합니다. 만약 그룹 간 변동이 크다면 (즉, 그룹 간 평균 차이가 크다면), F-통계량이 유의하게 됩니다.

        분산분석은 일반적으로 하나의 요인을 가지고 있는 일원배치 분산분석과 두 개 이상의 요인을 가지고 있는 이원배치 분산분석으로 나뉩니다. 이를 통해 여러 집단 간의 평균 차이를 비교하고 효과적으로 검정할 수 있습니다.

        **용어 정리**
        *쌍별 비교[pairwise comparison] : 여러 그룹 중 두 그룹간의 가설검정
        *총괄 검정[omnibus test] : 여러 그룹 평균들의 전체 분산에 관한 단일 가설검정
        *분산분해[decomposition of variance] : 구성 요소 분리, 예를 들면 전체평균, 처리 평균, 잔차 오차로 부터 개별 값들에 대한 기여를 뜻함.
        *F통계량[F-statistic]: 그룹 평균간의 차이가 랜덤모델에서 예상되는 것에서 벗어나는 정도를 측정하는 표준화된 통계량
        *SS[sum of squares] : 어떤 평균으로부터의 편차들의 제곱합.

        3.8.1 F통계량

            -F 통계량은 분산 분석(ANOVA)에서 사용되는 통계량입니다. 주로 두 개 이상의 그룹 간의 평균 차이를 비교하는 데 사용됩니다.

            F 통계량은 그룹 간의 평균 제곱 (Mean Square Between, MSB)을 그룹 내의 평균 제곱 (Mean Square Within, MSW)으로 나눈 값입니다. 이는 그룹 간의 변동과 그룹 내의 변동을 비교하여 그룹 간의 차이가 우연에 의한 것인지를 판단하는 데 사용됩니다.

            * 그룹 간의 평균 제곱 (MSB): 그룹 간의 변동을 자유도로 나눈 값입니다. 즉, 그룹 간의 차이가 얼마나 큰지를 측정합니다.
            * 그룹 내의 평균 제곱 (MSW): 그룹 내의 변동을 자유도로 나눈 값입니다. 즉, 그룹 내의 차이가 얼마나 큰지를 측정합니다.

            F 통계량은 그룹 간의 평균 차이가 우연에 의한 것인지를 판단하는 데 사용됩니다. F 값이 클수록 그룹 간의 차이가 통계적으로 유의하다는 것을 나타냅니다. 따라서, F 통계량을 사용하여 ANOVA에서 귀무가설을 검정하고, 그룹 간의 평균 차이를 평가할 수 있습니다.

        3.8.2 이원 분산분석

            - 이원 분산 분석(ANOVA)은 두 개 이상의 독립 변수(요인)가 종속 변수에 미치는 영향을 평가하는 통계적 기법입니다. 이 분석은 실험 설계에서 두 가지 이상의 요인이 종속 변수에 미치는 영향을 동시에 평가하는 데 사용됩니다.

            예를 들어, 약의 효과를 평가하는 실험에서 약물의 종류와 운동량이 두 개의 요인으로 작용할 수 있습니다. 이원 분산 분석을 사용하여 약물의 종류와 운동량이 혈압에 미치는 영향을 동시에 평가할 수 있습니다.

        이원 분산 분석은 다음과 같은 가정을 기반으로 합니다:

            1. 독립 변수들은 서로 독립적이어야 합니다.
            2. 종속 변수는 정규 분포를 따라야 합니다.
            3. 그룹 간의 오차는 등분산성을 가져야 합니다.

        이원 분산 분석은 다음과 같은 세 가지 주요 요소를 평가합니다:

            1. 각 요인의 주효과(Main Effects): 각 요인이 종속 변수에 미치는 영향을 평가합니다.
            2. 상호 작용 효과(Interaction Effects): 두 요인 간의 상호 작용이 종속 변수에 미치는 영향을 평가합니다.
            3. 오차(Residuals): 모형에 포함되지 않은 다른 요인이나 랜덤한 요인으로 인한 오차를 평가합니다.

        이원 분산 분석은 실험 설계에 따라 두 요인이 종속 변수에 미치는 영향을 정확하게 이해하고 해석하는 데 도움이 됩니다.

    3.9 카이제곱검정

        -카이제곱 검정(Chi-square test)은 범주형 자료의 독립성을 검정하는 통계적 방법입니다. 주로 두 개 이상의 범주형 변수 간의 관계가 있는지를 확인하는 데 사용됩니다.

        주요 사용 사례는 다음과 같다:

            1. 카이제곱 독립성 검정 (Chi-square Test for Independence): 두 개 이상의 범주형 변수 간의 독립성을 검정합니다. 예를 들어, 성별과 선호하는 음료수 간의 관계를 조사할 때 사용될 수 있습니다. 이 검정은 두 변수 간의 관계가 우연에 의한 것인지를 확인합니다.
            2. 카이제곱 적합도 검정 (Chi-square Goodness of Fit Test): 하나의 범주형 변수가 기대되는 분포와 일치하는지를 확인합니다. 예를 들어, 주사위를 던져서 나오는 눈의 분포가 균일한지를 확인할 때 사용될 수 있습니다.

        카이제곱 검정은 다음과 같은 가정에 기초한다:

            1. 한변수가 범주형이어야 합니다.
            2. 각 셀(카운트)의 기대도수가 충분히 큰 경우(보통 5 이상)에 적용됩니다.
            3. 셀 간의 관측된 빈도가 독립적이어야 합니다.

        카이제곱 검정은 관찰된 빈도와 예상되는 빈도 간의 차이를 측정하여 검정 통계량을 계산합니다. 이 검정 통계량은 자유도를 가진 카이제곱 분포를 따르며, 이를 통해 유의수준에서의 임계값을 비교하여 귀무가설을 검정합니다. 유의수준에서의 임계값보다 큰 검정 통계량은 귀무가설을 기각하고, 변수 간의 관계가 통계적으로 유의미하다는 것을 의미합니다.

        **용어정리**
            -카이제곱통계량[chi-square statistic] : 기대값으로부터 어떤 관찰값까지의 거리를 나타내는 측정치
            -기댓값[expectation(expected)] : 어떤가정(보통 귀무가설)으로부터 데이터가 발생할때, 그에 대해 기대하는 정도
            -d.f[degree of freedom] : 자유도

        3.9.1 카이제곱검정:재표본추출방법

            - 카이제곱 검정에서 재표본 추출은 통계적 추론을 수행하는 데 사용되는 일반적인 방법 중 하나입니다. 이 방법은 표본의 크기를 증가시키거나 표본을 다시 추출함으로써 통계적 특성을 추정하고 가설을 검정하는 데 사용됩니다.

            재표본추출 방법을 사용하여 카이제곱 검정을 수행하는 과정은 다음과 같습니다:

                1. 원래 표본 추출: 먼저 원래 데이터에서 표본을 추출합니다.
                2. 재표본 추출: 원래 표본에서 복원 추출 또는 비복원 추출을 사용하여 여러 번의 재표본을 생성합니다. 이 과정에서는 표본의 크기를 유지하거나 증가시키는 것이 일반적입니다.
                3. 카이제곱 통계량 계산: 각 재표본에 대해 카이제곱 통계량을 계산합니다. 이를 통해 각 표본에서 관측된 데이터와 예상되는 기대도수 간의 차이를 측정합니다.
                4. 재표본 분포 생성: 재표본에서 얻은 카이제곱 통계량을 사용하여 재표본 분포를 생성합니다. 이를 통해 표본 크기의 영향을 고려하여 카이제곱 통계량의 분포를 추정할 수 있습니다.
                5. 유의확률 계산: 재표본 분포를 사용하여 유의확률(재표본 p-값)을 계산합니다. 이는 귀무가설을 기각하는 데 필요한 통계적 증거를 제공합니다.
                6. 결과 해석: 재표본 p-값을 유의수준과 비교하여 귀무가설을 기각하거나 채택합니다. 만약 재표본 p-값이 유의수준보다 작다면, 귀무가설을 기각하고 대립가설을 채택할 수 있습니다.

            재표본추출 방법은 표본 크기가 작거나 표본이 비정규 분포를 따르는 경우에도 유용하게 사용될 수 있습니다. 또한 이 방법은 표본의 무작위성을 보장하고, 다양한 표본 크기에 대해 일관된 결과를 얻을 수 있는 장점이 있습니다.

        3.9.2 카이제곱검정: 통계적이론

            -카이제곱 검정은 관찰된 빈도와 기대 빈도 사이의 차이를 사용하여 범주형 변수 간의 관계를 평가하는 데 사용되는 통계적 방법입니다. 이론적으로 카이제곱 검정은 다음과 같은 단계로 진행됩니다:

                1. 귀무가설과 대립가설 설정: 카이제곱 검정의 첫 번째 단계는 귀무가설(H0)과 대립가설(H1)을 설정하는 것입니다. 귀무가설은 두 범주형 변수 사이에 관계가 없다는 것을 의미하며, 대립가설은 두 변수 사이에 관계가 있다는 것을 의미합니다.
                2. 예상 빈도 계산: 다음으로, 각 범주의 관찰된 빈도와 전체 데이터에서 예상되는 비율을 사용하여 예상 빈도를 계산합니다. 예상 빈도는 범주별로 관찰된 빈도가 어떤 값일 것으로 예상되는지를 나타냅니다.
                3. 카이제곱 통계량 계산: 실제 관찰된 빈도와 예상 빈도 사이의 차이를 계산하여 카이제곱 통계량을 얻습니다. 이 값은 두 변수 간의 관계의 적합도를 측정하는 데 사용됩니다.
                4. 유의확률 계산: 카이제곱 통계량을 자유도와 함께 사용하여 유의확률을 계산합니다. 이는 귀무가설을 기각하는 데 필요한 통계적 증거를 제공합니다.
                5. 결과 해석: 유의확률을 유의수준과 비교하여 귀무가설을 기각하거나 채택합니다. 만약 유의확률이 유의수준보다 작다면, 귀무가설을 기각하고 대립가설을 채택합니다. 따라서, 두 변수 간에는 통계적으로 유의한 관계가 있다고 결론을 내릴 수 있습니다.

            이러한 통계적 이론은 카이제곱 검정을 사용하여 범주형 변수 간의 관계를 평가하는 데 사용됩니다. 이를 통해 데이터의 분포가 기대되는 분포와 얼마나 일치하는지를 확인하고, 변수 간의 관계를 이해할 수 있습니다.

        3.9.3 피셔의 정확검정
            -피셔의 정확검정(Fisher's Exact Test)은 카이제곱 검정과 유사한 목적을 가지고 있지만, 표본 크기가 작거나 데이터가 특별한 구조를 가질 때 사용되는 검정 방법입니다. 주로 2x2 크로스테이블(교차표)을 분석하는 데 사용됩니다.

            피셔의 정확검정은 범주형 자료를 처리할 때 발생할 수 있는 한계점을 극복하기 위해 개발되었습니다. 이 검정은 직접적으로 관찰된 데이터의 확률과 같은 모집단 하에서 해당 결과가 나타날 확률을 계산하여 가설을 평가합니다.

            피셔의 정확검정은 다음과 같은 상황에서 주로 사용됩니다:

                1.표본 크기가 작을 때: 표본 크기가 작거나 예상되는 빈도가 작을 때 카이제곱 검정의 근사치가 부정확할 수 있습니다. 이러한 경우에 피셔의 정확검정을 사용하여 정확한 p-값을 계산할 수 있습니다.
                2.표본이 비균형적일 때: 카이제곱 검정은 표본이 균형적이거나 각 셀에 충분한 기대 빈도가 있는 경우에 적합합니다. 그러나 표본이 불균형적이거나 기대 빈도가 작은 경우에는 피셔의 정확검정이 더 적합할 수 있습니다.
                3.정확한 p-값이 필요한 경우: 피셔의 정확검정은 정확한 p-값을 계산하기 때문에 결과의 신뢰도를 높일 수 있습니다. 피셔의 정확검정은 카이제곱 검정보다 계산량이 많고 계산이 더 복잡할 수 있습니다. 그러나 표본이 작거나 비균형적인 경우에는 더 신뢰할 수 있는 결과를 제공할 수 있습니다.

        한문장요약 ! : 피셔의 정확검정은 작거나 불균형한 데이터에서 카이제곱 검정의 한계를 극복하여 정확한 p-값을 계산하는 검정 방법이다.

        3.9.4 데이터 과학과의 관련성

            - 데이터 과학은 데이터를 수집, 분석, 해석하여 통찰력을 얻고 의사 결정을 내리는 과정을 다루는 학문 분야입니다. 데이터 과학은 통계학, 컴퓨터 과학, 정보 기술 등 다양한 분야의 원리와 기술을 활용하여 데이터를 이해하고 활용합니다.

            데이터 과학은 데이터를 분석하여 정보와 지식을 추출하는 과정을 포함하며, 이를 통해 비즈니스 의사 결정이나 문제 해결에 도움이 되는 인사이트를 제공합니다. 이를 통해 기업은 시장 동향을 예측하고 비즈니스 전략을 개발할 수 있으며, 과학 연구에서는 새로운 발견을 이루고 문제를 해결하는 데 활용됩니다.

            데이터 과학은 데이터를 효과적으로 수집, 저장, 처리, 분석하는 기술과 방법론을 개발하고 적용하는 것을 목표로 합니다. 따라서 데이터 과학은 통계학과 밀접한 관련이 있으며, 데이터 분석을 위한 다양한 통계적 기법을 사용합니다. 또한 데이터 과학은 컴퓨터 과학과도 관련이 있으며, 데이터 처리 및 분석을 위한 알고리즘과 소프트웨어 개발에 대한 지식이 필요합니다.

            데이터 과학은 현대 사회에서 매우 중요한 역할을 하고 있으며, 기업, 학계, 정부 등 다양한 분야에서 활발하게 연구 및 적용되고 있습니다. 데이터 과학의 발전은 새로운 기술과 서비스의 발전을 촉진하고, 사회와 경제의 변화를 이끌어내는 중요한 요소 중 하나입니다.

        한문장 요약 ! "
            - 데이터 과학은 데이터를 수집, 분석, 해석하여 통찰력을 얻고 의사 결정을 내리는 학문 분야로, 통계학과 컴퓨터 과학의 원리와 기술을 활용하여 데이터를 이해하고 활용합니다. 데이터 과학은 비즈니스 의사 결정이나 과학 연구에서 인사이트를 추출하여 문제 해결과 비즈니스 전략 개발에 기여합니다.

    3.10 멀티암드 밴딧 알고리즘
        - 멀티암드 밴딧(Multi-Armed Bandit) 알고리즘은 선택지(슬롯 머신) 중에서 최적의 선택지를 찾기 위해 사용되는 기계 학습 문제입니다. 이 알고리즘은 탐색(exploration)과 활용(exploitation) 사이의 균형을 유지하면서 각 선택지의 기대 보상을 추정하고, 최적의 선택지를 선택하는 것을 목표로 합니다.

        멀티암드 밴딧 문제는 다음과 같은 상황을 가정합니다:
            여러 개의 슬롯 머신(팔)이 있고, 각 팔은 서로 다른 확률 분포를 가진 보상을 제공합니다.
            목표는 제한된 시도 횟수 내에서 최대의 총 보상을 얻기 위해 어느 팔을 당겨야 할지를 결정하는 것입니다.

        멀티암드 밴딧 알고리즘의 주요 방법은 다음과 같습니다:
            ε-탐욕적(ε-greedy) 알고리즘:
                일정 확률 ε로 임의의 팔을 탐색하고, 나머지 확률(1-ε)로 현재까지의 보상이 가장 높은 팔을 선택합니다.
            UCB(Upper Confidence Bound) 알고리즘:
                각 팔의 평균 보상과 그 팔의 탐색 횟수를 기반으로 신뢰 구간을 계산하여, 신뢰 구간의 상한이 가장 높은 팔을 선택합니다.
            톰슨 샘플링(Thompson Sampling):
                각 팔의 보상 분포를 베이지안 방식으로 모델링하여, 각 시도마다 확률적으로 팔을 선택합니다.

        멀티암드 밴딧 알고리즘은 광고 배치, 임상 시험, 추천 시스템 등 다양한 분야에서 활용됩니다. 이 알고리즘은 탐색과 활용의 균형을 유지하여 최적의 선택지를 효율적으로 찾을 수 있도록 돕습니다.

        **용어정리**
            - 멀티암드 배딧(MAB)multi-armed bandit: 고객이 선택 할수 있는 손잡이가 여러 개인가상의 슬롯머신을 말하며, 각 손잡이는 각기 다른 수익을 가져다 준다. 다중처리실험에 대한 비유라고 생각할 수 있다.
            -손잡이[arm] - 실험에서 어떤 하나의 처리를 말한다(예를 들면 '웹 테스트에서 헤드라인 A')
            -상급 수익 - 슬롯머신으로 딴 상금에 대한 실험적 비유유(예를 들면 '고객들의 링크 클릭 수)

    3.11 검정력과 표본크기
        1. 검정력 (Power):
            * 정의: 검정력은 실제로 대립가설이 참일 때, 귀무가설을 기각하는 확률입니다. 즉, 실제 효과가 존재할 때 이를 검출해내는 능력을 나타냅니다.
            * 계산: 검정력은 1 - β (제2종 오류 확률)로 계산됩니다. 제2종 오류는 실제로 대립가설이 참임에도 불구하고 귀무가설을 기각하지 못하는 오류입니다.
            * 의의: 검정력이 높을수록 실제 효과를 놓치지 않고 발견할 가능성이 커집니다. 일반적으로 검정력은 0.8 (80%) 이상이 권장됩니다.

        2. 표본 크기 (Sample Size):
            *정의: 표본 크기는 연구에서 데이터를 수집한 개체 수를 의미합니다.
            *영향: 표본 크기가 크면, 통계적 검정의 검정력이 증가합니다. 이는 표본이 클수록 모집단의 특성을 더 정확하게 반영할 수 있기 때문입니다.
            *계산: 표본 크기를 결정할 때 고려해야 할 요소는 검정력, 유의수준(α), 효과 크기, 모집단의 변동성 등입니다.

        검정력과 표본 크기의 관계:

            1. 표본 크기 증가: 표본 크기를 늘리면 표본의 변동성이 줄어들고, 효과를 더 명확하게 감지할 수 있어 검정력이 증가합니다.
            2. 검정력 증가: 높은 검정력을 얻기 위해 필요한 표본 크기를 계산할 수 있습니다. 이는 연구 설계 단계에서 중요합니다.

        **용어정리**
            -효과크기[effect size] - '클릭률의 20%향상'과 같이 통계검정을통해 판단할 수 있는 효과의 최소크기
            -검정력[power] - 주어진 표본크기로 주어진 효과크기를 알아낼 확률
            -유의수준[significance lever] - 검증시 사용할 통계 유의수준

        3.11.1 표본크기

            -표본 크기는 통계적 분석에서 데이터 수집의 단위 수를 나타내며, 연구의 정확성, 신뢰성, 검정력 등에 중요한 영향을 미칩니다. 적절한 표본 크기를 설정하는 것은 연구 결과의 유의성과 신뢰성을 확보하기 위해 필수적입니다.
            다음은 표본 크기와 관련된 주요 개념들입니다:

            * 표본 크기의 중요성
                1. 정확성 증가:
                    표본 크기가 크면 모집단의 특성을 더 잘 반영할 수 있습니다.
                    평균, 비율 등의 추정치의 오차가 줄어듭니다.
                2. 검정력 향상:
                    검정력은 실제 효과가 있을 때 이를 발견할 확률입니다.
                    표본 크기가 클수록 검정력이 높아져서 실제 효과를 더 잘 검출할 수 있습니다.
                3. 유의미한 결과 도출:
                    충분한 표본 크기를 통해 연구 결과의 통계적 유의성을 확보할 수 있습니다.
                    유의수준(α)과 검정력(1-β)에 기반한 표본 크기 설정이 필요합니다.

            * 표본 크기 결정 요소
                표본 크기를 결정할 때 고려해야 할 주요 요소들은 다음과 같습니다:

                1.유의수준 (α):흔히 0.05로 설정되며, 귀무가설이 참일 때 이를 기각할 확률입니다.
                2.검정력 (1-β):일반적으로 0.8 또는 0.9로 설정되며, 실제 효과가 있을 때 이를 검출할 확률입니다.
                3.효과 크기 (Effect Size):연구에서 관찰하고자 하는 최소한의 효과 크기입니다.
                표본 크기는 검출하고자 하는 효과 크기에 비례합니다. 작은 효과를 검출하려면 더 큰 표본이 필요합니다.
                4.변동성 (Variance):모집단의 변동성(또는 표준편차)이 클수록 더 큰 표본이 필요합니다.

            *표본 크기 계산 방법
                표본 크기는 다양한 방법으로 계산될 수 있습니다. 여기 몇 가지 예시를 들어보겠습니다:
                    1.단순 비교:
                    두 집단 간의 평균 차이를 비교할 때 사용하는 방법입니다.
                    예: 두 약물의 효과를 비교하는 경우.
                    2.비율 비교:
                    두 집단 간의 비율 차이를 비교할 때 사용하는 방법입니다.
                    예: 두 그룹의 치료 성공률을 비교하는 경우.
        [[요약]]
            표본 크기는 연구의 정확성과 검정력을 보장하는 중요한 요소입니다.
            유의수준, 검정력, 효과 크기, 변동성을 고려하여 표본 크기를 결정해야 합니다.
            충분한 표본 크기는 신뢰할 수 있는 연구 결과를 얻는 데 필수적입니다.

CHAP 3장 전체 요약 -

        1.머신러닝: 데이터에서 패턴을 학습하여 예측이나 의사 결정을 수행하는 인공 지능 분야입니다.
        2.지도학습: 입력 데이터와 그에 상응하는 정답(레이블)을 사용하여 모델을 학습시키는 머신러닝 방법입니다.
        3.2차원, 3차원, 4차원: 데이터의 특성을 나타내는 공간의 수를 의미하며, 2차원은 평면, 3차원은 공간, 4차원은 시간 등 추가 차원을 나타냅니다.
        4.유의성 검정: 데이터로부터 얻은 결과가 우연에 의한 것인지를 확인하는 통계적 방법입니다.
        5.A-B 검정: 두 가지 변형(A와 B)을 비교하여 어떤 변형이 더 우수한지를 판별하는 실험적 방법입니다.
        6.대조군: 실험에서 다른 처리를 받지 않는 기준 그룹으로, 결과 비교를 위해 사용됩니다.
        7.가설 검정: 주어진 데이터를 사용하여 특정 가설에 대한 적합성을 통계적으로 검정하는 과정입니다.
        8.대립가설, 일원/이원 가설검정: 실험에서 주장하려는 가설로, 일원은 한 변수, 이원은 두 변수를 검정합니다.
        9.귀무가설: 실험에서 특정 효과가 없다고 가정하는 가설입니다.
        10.재표본추출: 데이터로부터 복제된 여러 표본을 생성하여 통계적 추론을 수행하는 방법입니다.
        11.순열검정: 데이터를 무작위로 재배열하여 가설을 검정하는 비모수적 방법입니다.
        12.웹 점착성, 전체 및 부트스트랩 순열검정: 웹사이트의 사용자 경험을 측정하기 위한 방법으로, 부트스트랩 순열검정은 샘플링 점착성을 비교하는 통계적 방법입니다.
        13.통계적 유의성과 p값: 통계적 유의성은 특정 결과가 우연에 의한 것인지를 나타내며, p값은 귀무가설이 참일 때 해당 결과를 관찰할 확률을 나타냅니다.
        14.유의수준, 제1종과 제2종 오류: 유의수준은 귀무가설을 기각할 기준, 제1종 오류는 실제로는 참인데 거짓으로 기각하는 오류, 제2종 오류는 실제로 거짓인데 참으로 유지하는 오류를 의미합니다.
        15.t 검정: 두 집단의 평균을 비교하는 통계적 방법입니다.
        16.다중검정, 자유도, 분산분석: 다중검정은 여러 개의 가설을 동시에 검정하는 과정, 자유도는 독립적인 정보의 수, 분산분석은 세 개 이상의 집단 간의 평균 차이를 비교하는 통계적 방법입니다.
        17.투키의 HSD: 집단 간 평균의 유의미한 차이를 찾기 위한 사후 검정 방법입니다.
        18.F통계량: 분산분석에서 그룹 간 변동과 그룹 내 변동의 비율을 나타내는 통계량입니다.
        19.이원 분산분석: 두 개의 요인을 동시에 고려하여 그룹 간 평균 차이를 비교하는 통계적 방법입니다.
        20.카이제곱 검정: 관찰된 빈도와 기대 빈도 사이의 차이를 사용하여 범주형 변수 간의 관계를 평가하는 통계적 방법입니다.
        21.피셔의 정확검정: 작은 표본 크기나 기대 빈도가 작을 때 정확한 p-값을 계산하기 위해 사용하는 비모수적 검정 방법입니다.
        22.검정력과 표본 크기: 검정력은 실제 효과를 검출할 확률이고, 표본 크기는 데이터 수집 단위의 수로, 둘은 가설 검정의 유효성과 정확성에 큰 영향을 미칩니다.
        23.표본크기 : 표본 크기는 연구의 정확성과 검정력을 보장하는 중요한 요소입니다.

---

CHAP4 회귀와 예측 BEGIN

강사자님 말-- 책에 없는 내용 --
지도 학습 - 타겟이 있는 학습 네임이 붙어 있는학습
비지도 학습 - 타겟이 없고 데이터 알고리즘에 인해서 그룹화를 하는것

    * 지도학습 (Supervised Learning):
        지도학습은 입력과 해당하는 출력 사이의 관계를 학습하는 기계학습의 분야입니다.
        모델은 레이블된 데이터(입력과 해당하는 출력 쌍)를 사용하여 학습됩니다.
        예시:
            분류(Classification): 이메일이 스팸인지 아닌지를 예측하는 것과 같이 미리 정의된 클래스 중 하나로 데이터 포인트를 분류합니다.
            회귀(Regression): 주택 가격이나 주식 가격과 같은 연속적인 값에 대한 예측을 수행합니다.

    * 비지도학습 (Unsupervised Learning):
        비지도학습은 레이블이 없는 데이터에서 패턴이나 구조를 발견하는 기계학습의 분야입니다.
        모델은 레이블이 없는 데이터만을 사용하여 학습됩니다.
        예시:
            군집화(Clustering): 비슷한 특성을 갖는 데이터 포인트들을 그룹으로 묶습니다.
            차원 축소(Dimensionality Reduction): 데이터의 특성을 보존하면서 고차원 데이터를 저차원으로 압축합니다.

    요약하면, 지도학습은 입력과 출력 간의 관계를 학습하고 예측하는 반면, 비지도학습은 데이터의 내재된 구조나 패턴을 발견하거나 요약하는 데 중점을 둔다.

    4.1 단순선형회귀
        - 단순선형회귀(Simple Linear Regression)는 하나의 독립 변수와 하나의 종속 변수 간의 선형 관계를 모델링하는 통계적 기법입니다. 이 모델은 독립 변수(x)와 종속 변수(y) 간의 선형 관계를 설명하는 직선을 생성합니다. 주로 독립 변수가 종속 변수에 미치는 영향을 분석하고 예측하는 데 사용됩니다. 회귀 분석에서 가장 간단한 형태로, 직선의 방정식을 통해 독립 변수와 종속 변수 간의 관계를 모델링합니다.

    **용어정리**
        -응답변수 (Response Variable 또는 Dependent Variable):분석하고자 하는 현상에 대한 관심 대상이며, 종속 변수로도 불립니다. 주로 예측하거나 설명하려는 변수입니다.
        -독립변수 (Predictor Variable 또는 Independent Variable):종속 변수에 영향을 주는 변수로, 설명 변수로도 불립니다. 예측에 사용되는 변수입니다.
        -레코드 (Record 또는 Observation):데이터 집합에서 한 행을 나타내며, 하나의 관측치를 포함합니다. 하나의 레코드는 독립 변수와 종속 변수의 값으로 구성됩니다.
        -절편 (Intercept):회귀선이 y축과 만나는 점을 나타내는 값으로, 독립 변수가 0일 때의 종속 변수의 예측값을 의미합니다.
        -회귀계수 (Regression Coefficient):독립 변수와 종속 변수 간의 관계를 설명하는 기울기를 나타내는 값으로, 회귀선의 기울기를 의미합니다.
        -적합값 (Fitted Value):회귀 모델을 사용하여 예측된 종속 변수의 값으로, 모델이 주어진 독립 변수에 대해 예측하는 값입니다.
        -잔차 (Residual):실제 관측값과 회귀 모델로 예측한 값 사이의 차이를 의미합니다. 잔차는 회귀 모델의 적합도를 평가하는 데 사용됩니다.
        -최소제곱 (Least Squares):회귀선과 실제 관측값 사이의 잔차 제곱의 합을 최소화하여 회귀 모델을 적합시키는 방법을 의미합니다. 이 방법은 회귀 모델의 파라미터를 추정하는 데 사용됩니다.

    4.1.1 회귀식
        회귀식은 회귀 분석을 통해 독립 변수와 종속 변수 간의 관계를 나타내는 수학적 모델을 의미합니다. 일반적으로 회귀식은 다음과 같은 형태를 가집니다:

        "y=β0​+β1​x"

        여기서:
        yy는 종속 변수(응답 변수)를 나타냅니다.
        xx는 독립 변수(설명 변수)를 나타냅니다.
        β0β0​는 절편을 나타내며, 회귀선이 y축과 만나는 점의 값입니다.
        β1β1​는 회귀계수를 나타내며, 독립 변수와 종속 변수 간의 관계를 설명하는 기울기입니다.
        또한, 회귀식을 사용하여 주어진 독립 변수 값에 대해 종속 변수의 값을 예측할 수 있습니다. 또한, 회귀식을 통해 독립 변수와 종속 변수 간의 관계를 이해하고 해석할 수 있습니다.

    4.1.2 적합값과 잔차

        1. 적합값(Fitted Value):
            *적합값은 회귀 모델을 사용하여 독립 변수의 값에 대한 종속 변수의 예측값을 나타냅니다.
            *회귀 모델이 주어진 독립 변수의 값에 대해 예측한 종속 변수의 값입니다.
            *회귀 모델을 통해 예측된 종속 변수 값으로, 모델이 데이터에 얼마나 잘 맞는지를 평가하는 데 사용됩니다.

        2. 잔차(Residual):
            *잔차는 실제 관측값과 회귀 모델로 예측한 값 사이의 차이를 나타냅니다.
            *즉, 잔차는 관측된 종속 변수 값과 회귀 모델로 예측된 값 간의 오차를 나타냅니다.
            *잔차는 회귀 모델의 예측 오차를 나타내며, 모델이 데이터를 얼마나 잘 설명하고 있는지를 평가하는 데 사용됩니다.
            *잔차가 작을수록 모델이 데이터를 더 잘 설명한다고 볼 수 있습니다.

        적합값은 회귀 모델이 예측한 종속 변수의 값으로, 잔차는 실제 관측값과 예측값 간의 차이로 모델의 정확성을 평가하는 데 사용됩니다. 함께 사용하여 회귀 모델의 적합��를 평가���고 모델의 예측력을 이해하는 데 도움이 됩니다.

    4.1.3 최소제곱(Least Squares):

        * 최소제곱은 회���� 모델을 적합시킬 때 사용되는 기�� 중 하나입니다.
        * 회귀 모델은 종속 변����와 독립 변�� 간의 관계를 설명하는 직선이나 곡선으로 나타낼 수 있습니다.
        * 최소제곱은 회귀선과 실제 데이터 포인트 간의 거리(잔차)를 최소화하는 방법입니다.
        * 즉, 회귀선으로부터 관측값까지의 거리를 제곱하여 모두 더한 값이 최소가 되도록 회귀 모델을 조정합니다.
        * 최소제곱 방법을 사용하여 회귀 모델을 적합시키면, 회귀 계수와 절편을 추정할 수 있습니다.

    4.1.4. 예측 대 설명(프로파일링):

        * 예측 대 설명은 회귀 모델을 통해 얻은 결과를 해석하고 이해하는 과정입니다.
        * 예측은 회귀 모델을 사용하여 새로운 독립 변수 값에 ����한 ������� ���수 값을 예측하는 것을 의미합니다.
        * 설명은 회귀 모델의 독립 ���수들이 종속 변수에 미치는 영향을 이해하고 해석하는 것을 의미합니다.
        * 프로파일링 과정에서는 회귀 계수의 크기와 방향, 변수의 중요성 등을 분석하여 각 독립 변수가 종속 변수에 어떻게 영향을 미치는지 이해하고 설명합니다.
        * 이를 통해 회귀 모델이 데이터를 얼마나 잘 설명하고 있는지를 판단할 수 있습니다.

    4.2 다중선형회귀

        *다중선형회귀(Multiple Linear Regression)는 하나의 종속 변수와 둘 이상의 독립 변수 간의 선형 관계를 모델링하는 통계적 기법입니다. 다중선형회귀는 단순선형회귀와 달리, 둘 이상의 독립 변수가 종속 변수에 영향을 미치는 경우에 사용됩니다.

        " y=β0​+β1​x1​+β2​x2​+…+βn​xn​+ϵ "

        * yy는 종속 변수(응답 변수)를 나타냅니다.
        * x1,x2,…,xnx1​,x2​,…,xn​은 독립 변수(설명 변수)들을 나타냅니다.
        * β0,β1,β2,…,βnβ0​,β1​,β2​,…,βn​은 회귀계수를 나타내며, 각 독립 변수의 영향을 설명하는 계수입니다.
        * ϵ은 모델의 잔차를 나타냅니다.

        다중선형회귀 모델을 통해 여러 독립 변수들과 종속 변수 간의 관계를 모델링할 수 있으며, 이를 통해 독립 변수들이 종속 변수에 미치는 영향을 분석할 수 있습니다.

    **용어정리**
        제곱근평균제곱오차 (Root Mean Square Error, RMSE):
            * 예측 값과 실제 값 간의 차이를 나타내는 오차의 제곱을 평균한 후 제곱근을 취한 값입니다.
            * RMSE가 작을수록 모델의 예측이 실제 값과 가깝다고 볼 수 있습니다.

        잔차표준오차 (Residual Standard Error, RSE):
            *회귀 분석에서 잔차의 표준 편차를 나타내는 지표입니다.
            *모델이 관찰값을 설명하는 정도를 측정하며, 작을수록 모델이 더 잘 설명한다고 할 수 있습니다.

        R제곱 (Coefficient of Determination, R-squared):
            *종속 변수의 총 변동 중 모델로 설명되는 변동의 비율을 나타내는 지표입니다.
            *0에서 1 사이의 값을 가지며, 1에 가까울수록 모델이 데이터를 잘 설명한다고 할 수 있습니다.

        t통계량 (t-Statistic):
            * 회귀 모델에서 각 회귀 계수의 유효성을 검정하는 데 사용되는 지표입니다.
            * t통계량은 회귀 계수를 표준 오차로 나눈 값으로, 회귀 계수가 유의한지를 판단하는 데 사용됩니다.
        가중회귀 (Weighted Regression):
            * 회귀 분석에서 각 데이터 포인트에 가중치를 부여하여 모델을 적합시키는 방법입니다.
            * 가중회귀는 일반 회귀 분석에서 모든 데이터 포인트를 동일하게 취급하는 한계를 극복하기 위해 사용됩니다.

    4.2.1 킹 카운티 주택 정보 예제티
    4.2.2 모형 평가
        제곱근 평균제곱오차

        잔차 표준오차
