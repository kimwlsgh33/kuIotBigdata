# Machine Learning

7.3 계층적 클러스터링

    계층적 클러스터링(hierarchical clustering)은 데이터 포인트를 그룹화하는 방법 중 하나로, 두 가지 주요 접근 방식이 있습니다: 병합적(agglomerative) 방법과 분할적(divisive) 방법입니다.

    **용어정리**
    덴드로그램[dendrogram] : 레코드들, 그리고 레코드들이 속한 계층적 클러스터를 시각적으로 표현
    거리[distance] : 한 레코드가 다른 레코드들과 얼마나 가까운지를 보여주는 측정지표
    비유사도[dissimlarity] : 한 클러스터가 다른 클러스터들과 얼마나 가까운지를 보여주는 측정지표

    7.3.1 간단한 예제
    7.3.2 덴드로그램 (Dendrogram)

        *계층적 클러스터링의 결과를 시각적으로 표현하는 도구로, 클러스터링 과정에서 클러스터 간의 결합 순서를 나무 형태로 나타냅니다.
        *덴드로그램의 높이는 클러스터 간의 거리 또는 유사성을 나타내며, 클러스터의 결합 또는 분할을 이해하는 데 유용합니다.

        장점과 단점
        장점:

            클러스터 수를 미리 지정할 필요가 없습니다.
            클러스터 구조를 덴드로그램으로 시각화하여 이해하기 쉽습니다.
            여러 클러스터링의 가능성을 탐색할 수 있습니다.

        단점:
            계산 비용이 높습니다. (병합적 방법의 경우 O(n^3))
            큰 데이터셋에는 부적합할 수 있습니다.
            초기 데이터 포인트 간의 거리 측정에 민감합니다.

    7.3.3 병합 알고리즘

        병합적 계층적 클러스터링의 병합 과정은 다음과 같은 단계를 거칩니다

        초기화:
            * 각 데이터 포인트를 하나의 클러스터로 간주하여 시작합니다.

        반복 병합:
            * 모든 클러스터 간의 비유사도를 계산합니다.
            * 가장 비유사도가 작은 두 클러스터를 합칩니다.
            * 새로운 클러스터 간의 비유사도를 업데이트합니다.
            * 모든 데이터가 하나의 클러스터가 될 때까지 이 과정을 반복합니다.

    7.3.4 비유사도 측정

        비유사도(Dissimilarity)는 계층적 클러스터링에서 두 클러스터 간의 거리를 측정하는 방법입니다. 각 비유사도 측정 방법은 클러스터를 병합하는 방식에 영향을 미치며, 클러스터의 형태와 구조에 큰 영향을 줍니다. 여기서는 완전연결, 단일연결, 평균연결, 최소분산 방법에 대해 자세히 설명하겠습니다.

        비유사도 측정 방법 요약

            *단일연결: 가장 가까운 두 점의 거리 사용, 긴 클러스터 형성 가능.
            *완전연결: 가장 먼 두 점의 거리 사용, 더 구형 클러스터 형성.
            *평균연결: 모든 점 쌍의 평균 거리 사용, 중립적인 클러스터 형성.
            *워드기법 (Ward's Method): 클러스터 내 분산 최소화, 구형 클러스터 형성

7.4 모델 기반 클러스터링
모델 기반 클러스터링(Model-based Clustering)은 데이터가 특정 통계적 분포를 따른다고 가정하고 클러스터를 찾는 방법입니다. 여기서 주로 사용되는 모델 중 하나가 정규혼합 모델(Gaussian Mixture Model, GMM)입니다. 이 모델은 각 클러스터가 다변량 정규 분포를 따른다고 가정합니다.

    *정규혼합 모델 (Gaussian Mixture Model, GMM)
        GMM은 데이터가 여러 개의 다변량 정규 분포(가우시안 분포)의 혼합으로 구성되어 있다고 가정합니다. 각 가우시안 분포는 하나의 클러스터를 나타냅니다. GMM은 클러스터의 평균과 공분산을 통해 각 클러스터를 모델링합니다.

    7.4.1 다변량정규분포
        다변량 정규 분포(Multivariate Normal Distribution)는 여러 변수들이 상호 종속적으로 정규 분포를 따르는 분포입니다. 이는 단변량 정규 분포의 확장으로, 다차원 공간에서 정규 분포를 모델링합니다.

    7.4.2 정규혼합
    7.4.3 클러스터 개수 결정하기
        정규혼합 모델(Gaussian Mixture Model, GMM)에서 클러스터 개수를 결정하는 방법 중 하나로 베이지안 정보 기준(Bayesian Information Criterion, BIC)을 사용할 수 있습니다. BIC는 모델의 적합도와 복잡성 사이의 균형을 고려하여 최적의 모델을 선택하는 데 도움을 줍니다.

    베이즈 정보 기준 (BIC)

        *BIC는 모델의 로그 가능도(log-likelihood)에 모델의 복잡성을 고려하는 페널티(term)를 추가하여 계산됩니다. BIC 값이 낮을수록 모델이 더 적합하다고 간주합니다.

    주요개념
        *클러스터들이 각자 서로 다른 확률분포로부터 발생한 것으로 가정한다.
        *분포(일반적으로 정규분포) 개수에 대한 가정에 따라 서로 다른 적합한 모델이 있다.
        *이 방법은 너무 많은 파라미터(오버피팅의 원인이 될 수 있다)를 사용하지않으면서도 데이터에 적합한 모델을 선택한다.

7.5 스케일링과 범주형 변수

        **용어정리**
        *스케일링(scaling): 데이터의 범위를 늘리거나 줄이는 방식으로 여러 변수들이 같은 스케일에 오도록 하는 것
        *정규화(normalization): 원래 변수값에서 평균을 뺀 후에 표준편차로 나누는 방법으로, 스케일링의 일종이다.
        *고워거리(Gower's distance): 수치형과 범주형 데이터가 섞여있는 경우에 모든 변수가 0~1 사이로 오도록 하는 스케일링 방법.

    7.5.1 변수 스케일링 (Feature Scaling)

    변수 스케일링은 데이터의 특성(feature) 간에 존재하는 값의 범위 차이를 조정하는 과정입니다. 일반적으로 스케일링을 수행하는 이유는 다음과 같습니다:

        1.모델 성능 향상: 일부 머신러닝 알고리즘은 데이터의 스케일에 민감합니다. 스케일이 큰 특성은 모델 학습에 더 많은 영향을 미칠 수 있습니다.
        2.수렴 속도 향상: 경사 하강법과 같은 최적화 알고리즘은 스케일에 민감하여 스케일링을 통해 수렴 속도를 높일 수 있습니다.

    주요 스케일링 기법은 표준화(Standardization), 정규화(Normalization), 최소-최대 스케일링(Min-Max Scaling) 등이 있습니다.

    7.5.2 지배변수 (Dominant Variable)

    지배변수는 클러스터링 분석에서 가장 중요한 역할을 하는 변수를 가리킵니다. 지배변수를 식별하는 것은 클러스터링 결과를 해석하는 데 도움이 됩니다. 주로 주성분 분석(PCA)을 사용하여 지배변수를 식별하거나, 도메인 지식을 활용하여 중요한 변수를 선정합니다.

    7.5.3 범주형 데이터와 고워 거리
        범주형 데이터와 거리 측정

    범주형 데이터는 이산적인 값을 가지는 변수로, 거리 기반의 클러스터링 알고리즘에서는 직접적으로 사용할 수 없습니다. 이를 해결하기 위해 범주형 데이터를 숫자로 변환하는 인코딩 방법이 필요합니다. 일반적으로 원-핫 인코딩(One-Hot Encoding)을 사용하여 범주형 데이터를 이진 벡터로 변환합니다. 이를 통해 범주 간의 거리를 측정할 수 있습니다.

    7.5.4 혼합데이터의 클러스터링 문제

    혼합데이터는 수치형 데이터와 범주형 데이터가 혼합된 데이터를 의미합니다. 이러한 데이터를 클러스터링하는 것은 일반적인 클러스터링 문제보다 더 복잡합니다. 범주형 데이터를 어떻게 수치형 데이터와 함께 처리할지가 중요한 문제입니다. 일반적으로는 수치형 데이터는 변수 스케일링을 적용하고, 범주형 데이터는 원-핫 인코딩을 적용하여 데이터를 전처리한 후 클러스터링을 수행합니다.

    이러한 혼합데이터의 클러스터링 문제를 해결하기 위해 클러스터링 알고리즘을 수정하여 범주형 데이터를 처리할 수 있는 기능을 추가하는 경우도 있습니다. 예를 들어, k-평균 알고리즘의 확장인 k-평균 알고리즘 with Gower distance는 범주형 데이터를 고려한 거리 측정 방법을 사용하여 혼합데이터를 클러스터링할 수 있습니다.


    주요개념
        * 스케일이 서로 다른 변수들을 스케일이 비슷하도록 변환하여, 스케일이 알고리즘에 큰 영향을 미치지않도록한다.
        * 일반적인 스케일링 방법은 각 변수에서 평균을 빼고 표준편차로 나눠주는 정규화(표준화) 방법이다.
        * 또 다른 방법은 고워 거리를 사용하는 것이다. 이 방법은 모든변수를 0~1 범위로 스케일링한다.(수치형과 범주형데이터가 서로혼합된 경우에 많이 사용된다)
        * 변수 스케일링은 데이터 전처리의 중요한 단계이며, 클러스터링 분석에서 지배변수는 해석력을 높이는 데 도움이 됩니다. 범주형 데이터와 거리 측정 문제는 적절한 인코딩 방법을 선택하여 해결할 수 있으며, 혼합데이터의 클러스터링 문제는 데이터 전처리와 알고리즘 수정을 통해 처리할 수 있습니다.
